AWSTemplateFormatVersion: 2010-09-09
Description: Virtual Piano Template
Parameters:
  VirtualPianoWebsiteBucketName:
    Type: String
    Description: S3 Bucket name for virtual piano website
    Default: virtual-piano-997
  GitHubRepositoryURL:
    Type: String
    Description: URL for GitHub repository with virtual piano website files
    Default: https://raw.githubusercontent.com/NowakArtur97/Virtual-Piano/main
  FilesToCopyFromGitHub:
    Type: String
    Description: Virtual piano website files to copy from GitHub
    Default: index.html,style.css,piano.js,sounds/1.wav,sounds/1.5.wav,sounds/2.wav,sounds/2.5.wav,sounds/3.wav,sounds/4.wav,sounds/4.5.wav,sounds/5.wav,sounds/5.5.wav,sounds/6.wav,sounds/6.5.wav,sounds/7.wav,sounds/8.wav,sounds/8.5.wav,sounds/9.wav,sounds/9.5.wav,sounds/10.wav,sounds/11.wav,sounds/11.5.wav,sounds/12.wav,sounds/12.5.wav,sounds/13.wav,sounds/13.5.wav,sounds/14.wav,sounds/15.wav,
Resources:
  VirtualPianoWebsiteS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref VirtualPianoWebsiteBucketName
      PublicAccessBlockConfiguration:
        BlockPublicAcls: false
      OwnershipControls:
        Rules:
          - ObjectOwnership: ObjectWriter
      WebsiteConfiguration:
        IndexDocument: index.html
        ErrorDocument: index.html
  VirtualPianoWebsiteS3BucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref VirtualPianoWebsiteS3Bucket
      PolicyDocument:
        Id: VirtualPianoWebsiteS3BucketPolicy
        Version: 2012-10-17
        Statement:
          - Sid: PublicReadForGetBucketObjects
            Effect: Allow
            Principal: "*"
            Action: "s3:GetObject"
            Resource: !Sub "arn:aws:s3:::${VirtualPianoWebsiteS3Bucket}/*"
  GitHubToS3LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: "/"
      Policies:
        - PolicyName: GitHubToS3LambdaFunctionPolicies
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutObject
                Resource: !Sub "arn:aws:s3:::${VirtualPianoWebsiteS3Bucket}/*"
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "*"
  GitHubToS3LambdaInvoke:
    Type: AWS::CloudFormation::CustomResource
    DependsOn: GitHubToS3LambdaFunction
    Version: "1.0"
    Properties:
      ServiceToken: !GetAtt GitHubToS3LambdaFunction.Arn
  GitHubToS3LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Runtime: python3.13
      Timeout: 120
      Handler: index.lambda_handler
      Role: !GetAtt GitHubToS3LambdaRole.Arn
      Environment:
        Variables:
          BUCKET_NAME: !Ref VirtualPianoWebsiteS3Bucket
          GITHUB_URL: !Ref GitHubRepositoryURL
          FILES_TO_COPY: !Ref FilesToCopyFromGitHub
      Code:
        ZipFile: |
          import os
          import urllib.request
          import boto3
          from urllib.parse import urlparse
          import cfnresponse

          s3 = boto3.resource('s3')
          BUCKET_NAME = os.environ['BUCKET_NAME']
          GITHUB_URL = os.environ['GITHUB_URL']
          FILES_TO_COPY = os.environ['FILES_TO_COPY'].split(",")

          def save_to_local(url):
              urlPath = urlparse(url).path
              fileName = os.path.basename(urlPath)
              filePath = '/tmp/' + fileName
              urllib.request.urlretrieve(url, filePath)
              return filePath

          def copy_to_s3(url, folder, contentType):
              filePath = save_to_local(url)
              fileName = os.path.basename(filePath)
              s3.Object(BUCKET_NAME, folder + fileName).put(Body=open(filePath, 'rb'), ContentType=contentType)

          def resolve_content_type(file):
              extension = file.split(".")[1]
              if extension == "html":
                  return "text/html"
              elif extension == "css":
                  return "text/css"
              elif extension == "js":
                  return "text/javascript"
              elif extension == "py":
                  return "text/x-python"
              elif extension in ["jpeg", "jpg"]:
                  return "image/jpeg"
              elif extension == "png":
                  return "image/png"
              elif extension == "tiff":
                  return "image/tiff"
              elif extension == "bmp":
                  return "image/bmp"
              elif extension == "gif":
                  return "image/gif"
              elif extension in ["svg", "xml"]:
                  return "image/svg+xml"
              elif extension in ["mp3", "wav", "ogg"]:
                  return "audio/mpeg"
              elif extension == "pdf":
                  return "application/pdf"
              elif extension == "zip":
                  return "application/zip"
              elif extension == "yaml":
                  return "binary/octet-stream"
              else:
                  return "text/plain"

          def lambda_handler(event, context):
              responseData = {}
              requestType = event['RequestType']
              try:
                  if requestType == 'Create':
                      for fileToCopy in FILES_TO_COPY:
                          fileOnGitHub = GITHUB_URL + "/" + fileToCopy
                          print("File to copy: " + fileToCopy)
                          print("URL to file: " + fileOnGitHub)
                          folder = fileToCopy[:fileToCopy.rfind("/")] + '/' if '/' in fileToCopy else ''
                          contentType = resolve_content_type(fileToCopy)
                          copy_to_s3(fileOnGitHub, folder, contentType)
                          print("Successfully copied file: " + fileToCopy + " to bucket: " + BUCKET_NAME)
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
              except Exception as e:
                  print("Exception when copying files from GitHub to S3 bucket: " + BUCKET_NAME)
                  print(e)
                  cfnresponse.send(event, context, cfnresponse.FAILED, responseData)
  S3BucketCleanerLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: "/"
      Policies:
        - PolicyName: S3BucketCleanerLambdaFunctionPolicies
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - s3:ListBucket
                Resource: !Sub "arn:aws:s3:::${VirtualPianoWebsiteS3Bucket}"
              - Effect: Allow
                Action:
                  - s3:DeleteObject
                Resource: !Sub "arn:aws:s3:::${VirtualPianoWebsiteS3Bucket}/*"
  S3BucketCleanerLambdaInvoke:
    Type: AWS::CloudFormation::CustomResource
    Version: "1.0"
    Properties:
      ServiceToken: !GetAtt S3BucketCleanerLambdaFunction.Arn
  S3BucketCleanerLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Runtime: python3.13
      Timeout: 60
      Handler: index.lambda_handler
      Role: !GetAtt S3BucketCleanerLambdaRole.Arn
      Environment:
        Variables:
          BUCKETS_TO_CLEAN: !Ref VirtualPianoWebsiteS3Bucket
      Code:
        ZipFile: |
          import os.path
          import boto3
          import cfnresponse

          BUCKETS_TO_CLEAN = os.environ['BUCKETS_TO_CLEAN'].split(",")

          s3 = boto3.resource('s3')

          def clear_bucket(bucketName):
              s3.Bucket(bucketName).objects.all().delete()

          def lambda_handler(event, context):
              responseData = {}
              if event['RequestType'] == 'Delete':
                  for bucketName in BUCKETS_TO_CLEAN:
                      try:
                          clear_bucket(bucketName)
                          print("Successfully cleared bucket: " + bucketName)
                          cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
                      except Exception as e:
                          print('Exception when cleaning bucket: ' + bucketName)
                          print(e)
                          cfnresponse.send(event, context, cfnresponse.FAILED, responseData)
              else:
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
Outputs:
  VirtualPianoWebsiteUrl:
    Description: Virtual piano website url
    Value: !GetAtt VirtualPianoWebsiteS3Bucket.WebsiteURL
